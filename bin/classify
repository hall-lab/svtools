#!/usr/bin/env python

import argparse, sys, copy, gzip, os,time,math, re
import numpy as np
import pandas as pd
from scipy import stats
from collections import defaultdict
import statsmodels.api as sm
import statsmodels.formula.api as smf
from argparse import RawTextHelpFormatter
import warnings
import pickle
# from statsmodels.regression.mixed_linear_model import MixedLM
# from statsmodels.regression.mixed_linear_model import MixedLMParams

__author__ = "Abhijit Badve"
__version__ = "$Revision: 0.0.1 $"
__date__ = "$Date: 2015-11-10 14:31 $"
__revision__ = "Adapted Haley Abel's version in R"
# --------------------------------------
# define functions

def get_args():
    parser = argparse.ArgumentParser(formatter_class=RawTextHelpFormatter, description="\
classify\n\
author: " + __author__ + "\n\
version: " + __version__ + "\n\
description: classify structural variants")
    parser.add_argument('-t', '--tSet', metavar='String', dest='tSet', type=argparse.FileType('r'), default=sys.stdin, required=True, help='high quality deletions & duplications training dataset[vcf]/[stdin]')
    parser.add_argument('-i', '--input', metavar='VCF', dest='vcf_in', type=argparse.FileType('r'), default=None, help='test vcf input for applying a model')
    parser.add_argument('-o', '--output', metavar='VCF', dest='vcf_out', type=argparse.FileType('w'), default=sys.stdout, help='vcf output [stdout]')
    parser.add_argument('--debug', action='store_true', help='debugging verbosity')
    # parse the arguments
    args = parser.parse_args()
    # if no input, check if part of pipe and if so, read stdin.
    if args.vcf_in == None:
        if sys.stdin.isatty():
            parser.print_help()
            exit(1)
        else:
            args.vcf_in = sys.stdin
    # send back the user input
    return args

class Vcf(object):
    def __init__(self):
        self.file_format = 'VCFv4.2'
        # self.fasta = fasta
        self.reference = ''
        self.filter = ''
        self.sample_list = []
        self.info_list = []
        self.format_list = []
        self.alt_list = []
        self.add_format('GT', 1, 'String', 'Genotype')

    def add_header(self, header):
        for line in header:
            if line.split('=')[0] == '##fileformat':
                self.file_format = line.rstrip().split('=')[1]
            elif line.split('=')[0] == '##reference':
                self.reference = line.rstrip().split('=')[1]
            elif line.split('=')[0] == '##FILTER':
                self.filter = line.rstrip().split('=')[1]    
            elif line.split('=')[0] == '##INFO':
                a = line[line.find('<')+1:line.find('>')]
                r = re.compile(r'(?:[^,\"]|\"[^\"]*\")+')
                self.add_info(*[b.split('=')[1] for b in r.findall(a)])
            elif line.split('=')[0] == '##ALT':
                a = line[line.find('<')+1:line.find('>')]
                r = re.compile(r'(?:[^,\"]|\"[^\"]*\")+')
                self.add_alt(*[b.split('=')[1] for b in r.findall(a)])
            elif line.split('=')[0] == '##FORMAT':
                a = line[line.find('<')+1:line.find('>')]
                r = re.compile(r'(?:[^,\"]|\"[^\"]*\")+')
                self.add_format(*[b.split('=')[1] for b in r.findall(a)])
            elif line[0] == '#' and line[1] != '#':
                self.sample_list = line.rstrip().split('\t')[9:]
    # return the VCF header
    def get_header(self):
        if self.filter != '':        
            header = '\n'.join(['##fileformat=' + self.file_format,
                                '##fileDate=' + time.strftime('%Y%m%d'),
                                '##reference=' + self.reference,
                                '##filter=' + self.filter] + \
                               [i.hstring for i in self.info_list] + \
                               [a.hstring for a in self.alt_list] + \
                               [f.hstring for f in self.format_list] + \
                               ['\t'.join([
                                   '#CHROM',
                                   'POS',
                                   'ID',
                                   'REF',
                                   'ALT',
                                   'QUAL',
                                   'FILTER',
                                   'INFO',
                                   'FORMAT'] + \
                                          self.sample_list
                                      )]) + '\n'
        else:
            header = '\n'.join(['##fileformat=' + self.file_format,
                                '##fileDate=' + time.strftime('%Y%m%d'),
                                '##reference=' + self.reference] + \
                               [i.hstring for i in self.info_list] + \
                               [a.hstring for a in self.alt_list] + \
                               [f.hstring for f in self.format_list] + \
                               ['\t'.join([
                                   '#CHROM',
                                   'POS',
                                   'ID',
                                   'REF',
                                   'ALT',
                                   'QUAL',
                                   'FILTER',
                                   'INFO',
                                   'FORMAT'] + \
                                          self.sample_list
                                      )]) + '\n'
        return header

    def add_info(self, id, number, type, desc):
        if id not in [i.id for i in self.info_list]:
            inf = self.Info(id, number, type, desc)
            self.info_list.append(inf)

    def add_alt(self, id, desc):
        if id not in [a.id for a in self.alt_list]:
            alt = self.Alt(id, desc)
            self.alt_list.append(alt)

    def add_format(self, id, number, type, desc):
        if id not in [f.id for f in self.format_list]:
            fmt = self.Format(id, number, type, desc)
            self.format_list.append(fmt)

    def add_sample(self, name):
        self.sample_list.append(name)

    # get the VCF column index of a sample
    # NOTE: this is zero-based, like python arrays
    def sample_to_col(self, sample):
        return self.sample_list.index(sample) + 9

    class Info(object):
        def __init__(self, id, number, type, desc):
            self.id = str(id)
            self.number = str(number)
            self.type = str(type)
            self.desc = str(desc)
            # strip the double quotes around the string if present
            if self.desc.startswith('"') and self.desc.endswith('"'):
                self.desc = self.desc[1:-1]
            self.hstring = '##INFO=<ID=' + self.id + ',Number=' + self.number + ',Type=' + self.type + ',Description=\"' + self.desc + '\">'

    class Alt(object):
        def __init__(self, id, desc):
            self.id = str(id)
            self.desc = str(desc)
            # strip the double quotes around the string if present
            if self.desc.startswith('"') and self.desc.endswith('"'):
                self.desc = self.desc[1:-1]
            self.hstring = '##ALT=<ID=' + self.id + ',Description=\"' + self.desc + '\">'

    class Format(object):
        def __init__(self, id, number, type, desc):
            self.id = str(id)
            self.number = str(number)
            self.type = str(type)
            self.desc = str(desc)
            # strip the double quotes around the string if present
            if self.desc.startswith('"') and self.desc.endswith('"'):
                self.desc = self.desc[1:-1]
            self.hstring = '##FORMAT=<ID=' + self.id + ',Number=' + self.number + ',Type=' + self.type + ',Description=\"' + self.desc + '\">'

class Variant(object):
    def __init__(self, var_list, vcf):
        self.chrom = var_list[0]
        self.pos = int(var_list[1])
        self.var_id = var_list[2]
        self.ref = var_list[3]
        self.alt = var_list[4]
        if var_list[5] == '.':
            self.qual = 0
        else:
            self.qual = float(var_list[5])
        self.filter = var_list[6]
        self.sample_list = vcf.sample_list
        self.info_list = vcf.info_list
        self.info = dict()
        self.format_list = vcf.format_list
        self.active_formats = list()
        self.gts = dict()
        
        # fill in empty sample genotypes
        if len(var_list) < 8:
            sys.stderr.write('\nError: VCF file must have at least 8 columns\n')
            exit(1)
        if len(var_list) < 9:
            var_list.append("GT")

        # make a genotype for each sample at variant
        for s in self.sample_list:
            try:
                s_gt = var_list[vcf.sample_to_col(s)].split(':')[0]
                self.gts[s] = Genotype(self, s, s_gt)
                # import the existing fmt fields
                for j in zip(var_list[8].split(':'), var_list[vcf.sample_to_col(s)].split(':')):
                    self.gts[s].set_format(j[0], j[1])
            except IndexError:
                self.gts[s] = Genotype(self, s, './.')

        self.info = dict()
        i_split = [a.split('=') for a in var_list[7].split(';')] # temp list of split info column
        for i in i_split:
            if len(i) == 1:
                i.append(True)
            self.info[i[0]] = i[1]
    def set_info(self, field, value):
        if field in [i.id for i in self.info_list]:
            self.info[field] = value
        else:
            sys.stderr.write('\nError: invalid INFO field, \"' + field + '\"\n')
            exit(1)

    def get_info(self, field):
        return self.info[field]

    def get_info_string(self):
        i_list = list()
        for info_field in self.info_list:
            if info_field.id in self.info.keys():
                if info_field.type == 'Flag':
                    i_list.append(info_field.id)
                else:
                    i_list.append('%s=%s' % (info_field.id, self.info[info_field.id]))
        return ';'.join(i_list)

    def get_format_string(self):
        f_list = list()
        for f in self.format_list:
            if f.id in self.active_formats:
                f_list.append(f.id)
        return ':'.join(f_list)

    def genotype(self, sample_name):
        if sample_name in self.sample_list:
            return self.gts[sample_name]
        else:
            sys.stderr.write('\nError: invalid sample name, \"' + sample_name + '\"\n')

    def get_var_string(self):
        s = '\t'.join(map(str,[
            self.chrom,
            self.pos,
            self.var_id,
            self.ref,
            self.alt,
            '%0.2f' % self.qual,
            self.filter,
            self.get_info_string(),
            self.get_format_string(),
            '\t'.join(self.genotype(s).get_gt_string() for s in self.sample_list)
        ])) + '\n'
        return s

class Genotype(object):
    def __init__(self, variant, sample_name, gt):
        self.format = dict()
        self.variant = variant
        self.set_format('GT', gt)

    def set_format(self, field, value):
        if field in [i.id for i in self.variant.format_list]:
            self.format[field] = value
            if field not in self.variant.active_formats:
                self.variant.active_formats.append(field)
                # sort it to be in the same order as the format_list in header
                self.variant.active_formats.sort(key=lambda x: [f.id for f in self.variant.format_list].index(x))
        else:
            sys.stderr.write('\nError: invalid FORMAT field, \"' + field + '\"\n')
            exit(1)

    def get_format(self, field):
        return self.format[field]

    def get_gt_string(self):
        g_list = list()
        for f in self.variant.active_formats:
            if f in self.format:
                if type(self.format[f]) == float:
                    g_list.append('%0.2f' % self.format[f])
                else:
                    g_list.append(self.format[f])
            else:
                g_list.append('.')
        return ':'.join(map(str,g_list))

# # --------------------------------------
def parse_vcf(variants,vcf_file,vcf_out,logr,setA):
    epsilon=0.1
    in_header = True
    header = []
    vcf = Vcf()
    for line in vcf_file:
        if in_header:
            if line[0] == '#':
                header.append(line)
                if line[1] != '#':
                    vcf_samples = line.rstrip().split('\t')[9:]
                    in_header = False
                    vcf.add_header(header)
                    if vcf_out is not None:
                        vcf_out.write(vcf.get_header())
                continue
        v = line.rstrip().split('\t')
        var = Variant(v, vcf)
        if var.info["SVTYPE"] == "DEL" or var.info["SVTYPE"] == "DUP":
            count_hom = 0 
            unknowns = 0 
            for sample in vcf_samples:
                    if var.gts[sample].get_format('GT') != './.':
                        log2r = math.log((float(var.gts[sample].get_format('CN'))+ epsilon)/2,2)  #to avoid log(0)
                        logr[sample + var.info['SVTYPE'] + var.gts[sample].get_format('GT')].append(log2r)
                        setA.append([var.var_id,sample,var.info['SVTYPE'],\
                                             abs(float(var.info['SVLEN'])),\
                                             var.info['AF'],
                                             var.gts[sample].get_format('GT'),\
                                             var.gts[sample].get_format('CN'),\
                                             math.log(abs(float(var.info['SVLEN']))),
                                             log2r])
                    if var.gts[sample].get_format('GT') == '0/0':
                        count_hom += 1
                    if var.gts[sample].get_format('GT') == './.':
                        unknowns +=  1
            #GT is homozygous reference write it.
            if vcf_out is not None and count_hom == len(vcf_samples):
                  vcf_out.write(var.get_var_string())
                  continue
            #GT is unknown write it.      
            if vcf_out is not None and unknowns == len(vcf_samples):
                  vcf_out.write(var.get_var_string())
                  continue
            if variants is not None:
                variants[var.var_id] = copy.deepcopy(var)      
        else:
            if vcf_out is not None:
                vcf_out.write(var.get_var_string())
                
            
def write_output(var,vcf_out,nb_svtype):
    """write reclassified variants to a VCF"""
    if nb_svtype == "BND":
        for m_var in to_bnd(var):
            vcf_out.write(m_var.get_var_string())
    else:
        vcf_out.write(var.get_var_string())
def to_bnd(var):
    var1 = copy.deepcopy(var)
    var2 = copy.deepcopy(var)

    # update svtype
    var1.info['SVTYPE'] = 'BND'
    var2.info['SVTYPE'] = 'BND'

    # update variant id
    var1.info['EVENT'] = var.var_id
    var2.info['EVENT'] = var.var_id
    var1.var_id = var.var_id + "_1"
    var2.var_id = var.var_id + "_2"
    var1.info['MATEID'] = var2.var_id
    var2.info['MATEID'] = var1.var_id
    
    # update position
    var2.pos = var.info['END']

    # update CIPOS and CIEND
    var2.info['CIPOS'] = var.info['CIEND']
    var2.info['CIEND'] = var.info['CIPOS']
    var2.info['CIPOS95'] = var.info['CIEND95']
    var2.info['CIEND95'] = var.info['CIPOS95']

    # delete svlen and END
    del var1.info['SVLEN']
    del var2.info['SVLEN']
    del var1.info['END']
    del var2.info['END']

    # add SECONDARY to var2
    var2.info['SECONDARY'] = True

    if var.info['SVTYPE'] == 'DEL':
        var1.alt = 'N[%s:%s[' % (var.chrom, var.info['END'])
        var2.alt = ']%s:%s]N' % (var.chrom, var.pos)

    elif var.info['SVTYPE'] == 'DUP':
        var1.alt = ']%s:%s]N' % (var.chrom, var.info['END'])
        var2.alt = 'N[%s:%s[' % (var.chrom, var.pos)
    return var1, var2
    

def lowQuantile(xx):
    return np.percentile(xx,2.5)
def highQuantile(xx):
    return np.percentile(xx,97.5)
def lld(xx, mean, sd):
    ll = 1 / sd * math.exp(-(xx-mean) * (xx-mean) / (2*sd*sd))
    return ll
def p_mix(row):
    return row['lld0'] * row['p0'] + row['lld1'] * row['p1'] + row['lld2'] * row['p2']        
def find_max(row):
    return row.idxmax()
def reclass_nb_var(temp, p_cnv,frac_BND):
    #only returning naive Bayes classification output. MLE class is not used for now.
    tr = pd.DataFrame({'p0' : [1.0, 0.0,0.0],'p1' : [0.1, 0.45, 0.45],'p2' : [0.0, 0.5, 0.5],'gt' : ["0/0", "0/1", "1/1"]})
    temp = pd.merge(temp,tr, on='gt', how='left')
    #temp['p_mix'] = temp.apply(lambda row: p_mix(row['lld0'],row['p0'],row['lld1'],row['p1'],row['lld2'],row['p2']))
    #temp['num'] = p_cnv * temp['p_mix']
    #temp['reclass_nb'] = temp['reclass_mle'] = temp['svtype']
    temp['p_mix'] = temp['lld0'] * temp['p0'] + temp['lld1'] * temp['p1'] + temp['lld2'] * temp['p2']    
    #naive Bayes reclassification
    if p_cnv * np.prod(temp['p_mix'].as_matrix()) < (1- p_cnv) * np.prod(temp['lld0'].as_matrix()):
        return "BND"
    # reclass based on maximum likelihood--if the most likely configuration of genotypes has more than frac.BND wt call, reclassify as BND
    # mc = pd.DataFrame()
    # mc['maxpos'] = temp[['lld0','lld1','lld2']].apply(find_max,axis=1)
    # sum_mc = (mc == 'lld0').sum()['maxpos']
    # len_mc = len(mc)
    # if sum_mc > frac_BND * len_mc :
    #     temp["reclass_mle"] = "BND"
    return str(temp.loc[0,'svtype'])
def calc_params(training_vcf):
    frac_BND=0.25
    p_cnv=0.5  #prior pr
    tSet = list()
    tlog2r = defaultdict(list)
    tQuantileLow = defaultdict(list)
    tQuantileHigh = defaultdict(list)
    tSetAdj = list()
    parse_vcf(None,training_vcf,None,tlog2r,tSet)
    #  aggregatable dictionary
    for x in tSet:
        del x[0]
    [tQuantileLow[item].append(lowQuantile(tlog2r[item])) for item in tlog2r]
    [tQuantileHigh[item].append(highQuantile(tlog2r[item])) for item in tlog2r]
     # exclude data points where log2 copy ratio falls in extremes of distribution
    for item in tSet:
        if item[-1] <= tQuantileHigh[item[0]+ item[1] + item[4]][0] and \
           item[-1] >=  tQuantileLow[item[0]+ item[1]+ item[4]][0]:
            item.append(tQuantileHigh[item[0]+ item[1] + item[4]][0])
            item.append(tQuantileLow[item[0]+ item[1] + item[4]][0])
            tSetAdj.append(copy.deepcopy(item))
    #adjust copy number for small deletions (<1kb), no strong relationship b/w cn and size for dups
    small_het_dels = filter(lambda (sample,svtype,svlen,af,gt,cn,log_len,logr,q_high,q_low):svtype == 'DEL' and gt == '0/1' and float(svlen) < 1000, tSetAdj)
    small_hom_dels = filter(lambda (sample,svtype,svlen,af,gt,cn,log_len,logr,q_high,q_low):svtype == 'DEL' and gt == '1/1' and float(svlen) < 1000, tSetAdj)
    mean_hom_del = np.mean([item[7] for item in tSetAdj if item[1] == "DEL" and item[4] == "1/1" and float(item[2]) > 1000])
    mean_het_del = np.mean([item[7] for item in tSetAdj if item[1] == "DEL" and item[4] == "0/1" and float(item[2]) > 1000])
    ##########
    small_hom_dels = [copy.deepcopy(item) for item in small_hom_dels]
    small_het_dels = [copy.deepcopy(item) for item in small_het_dels]
    [item.append(float(item[7]) - mean_hom_del) for item in small_hom_dels]
    [item.append(float(item[7]) - mean_het_del) for item in small_het_dels]
    small_hom_dels = pd.DataFrame(data = small_hom_dels)
    small_hom_dels.columns = ['sample','svtype','svlen','af','gt','cn','logsz','logr','q_high','q_low','offset']
    small_het_dels = pd.DataFrame(data = small_het_dels)
    small_het_dels.columns = ['sample','svtype','svlen','af','gt','cn','logsz','logr','q_high','q_low','offset']
    tSetAdj = pd.DataFrame(data = tSetAdj)
    tSetAdj.columns = ['sample','svtype','svlen','af','gt','cn','logsz','logr','q_high','q_low']
    tSetAdj["logr_adj"] = tSetAdj["logr"]
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore")
        re_hom = smf.ols('offset~logsz',small_hom_dels)
        re_hom_m = re_hom.fit()
        with open('re_hom_m','w') as f:
          pickle.dump(re_hom_m,f)
        re_het = smf.ols('offset~logsz',small_het_dels)
        re_het_m = re_het.fit()
        with open('re_het_m','w') as f:
          pickle.dump(re_het_m,f)
    j = 0
    k = 0
    het_predict = re_het_m.predict(small_het_dels[["offset","logsz"]])
    hom_predict = re_hom_m.predict(small_hom_dels[["offset","logsz"]])
    for i in range(len(tSetAdj)):
        if (tSetAdj["svtype"][i] == 'DEL') &  (tSetAdj["gt"][i] == '0/1') & (tSetAdj["svlen"][i] < 1000):
            tSetAdj.loc[i,"logr_adj"] = tSetAdj.loc[i,"logr_adj"] - het_predict[j]
            j += 1
        elif (tSetAdj["svtype"][i] == 'DEL') &  (tSetAdj["gt"][i] == '1/1') & (tSetAdj["svlen"][i] < 1000):
            tSetAdj.loc[i,"logr_adj"] = tSetAdj.loc[i,"logr_adj"] - hom_predict[k]
            k += 1
    sds = pd.DataFrame()
    training_agg_mean_logr = tSetAdj[['sample','svtype','gt','logr_adj']].groupby(['sample','svtype','gt']).aggregate(np.mean)
    training_agg_sd_logr   = tSetAdj[['sample','svtype','gt','logr_adj']].groupby(['sample','svtype','gt']).aggregate(np.std)
    sds = pd.pivot_table(training_agg_sd_logr.reset_index(), values = 'logr_adj', index = ['sample','svtype'], columns = ['gt']).reset_index()
    means = pd.pivot_table(training_agg_mean_logr.reset_index(), values = 'logr_adj', index = ['sample','svtype'], columns = ['gt']).reset_index()
    params = pd.concat([sds,means], axis=1)[sum([range(0,5),range(7,10)],[])]
    params.columns = ['sample','svtype','sd0','sd1','sd2','mean0','mean1','mean2']
    return params
# apply model to reclassify test set
def classify(vcf_in,vcf_out,params,re_het_m,re_hom_m,debug):
    start = time.time()
    frac_BND = 0.25
    p_cnv = 0.5  #prior pr
    test_set = list()
    test_logr = defaultdict(list)
    variants = defaultdict(list)
    parse_vcf(variants, vcf_in, vcf_out, test_logr, test_set)
    test_set = pd.DataFrame(data = test_set)
    test_set.columns = ['var_id','sample','svtype','svlen','af','gt','cn','logsz','logr']
    test_set["logr_adj"] = test_set["logr"]
    small_hom_dels = small_het_dels = pd.DataFrame()
    small_hom_dels = test_set[((test_set["svtype"] == 'DEL') & (test_set["gt"] == '1/1') & (test_set["svlen"] < 1000))].reset_index()
    small_het_dels = test_set[((test_set["svtype"] == 'DEL') & (test_set["gt"] == '0/1') & (test_set["svlen"] < 1000))].reset_index()
    small_hom_dels["logr_adj"] = small_hom_dels["logr"] - re_hom_m.predict(small_hom_dels[["logr","logsz"]])
    small_het_dels["logr_adj"] = small_het_dels["logr"] - re_het_m.predict(small_het_dels[["logr","logsz"]])
    # only consider the subset of individuals that are not wildtype
    test_set_merged = pd.DataFrame()
    test_set[((test_set["svlen"] > 1000) & (test_set["gt"] == '0/0'))].to_csv("larger_homs.csv")
    test_set_merged = pd.concat([small_hom_dels,small_het_dels,\
                            test_set[((test_set["svlen"] > 1000) & (test_set["gt"]!= '0/0'))],\
                            test_set[((test_set["svlen"] < 1000) & (test_set["gt"]!= '0/0') & (test_set["svtype"] == 'DUP'))]],axis=0)
    test_set_merged = pd.merge(test_set_merged,params, how='left',on=['sample','svtype'],indicator=False)
    test_set_merged['lld0'] = test_set_merged.apply(lambda row:lld(row["logr_adj"], row["mean0"],row["sd0"]), axis=1)
    test_set_merged['lld1'] = test_set_merged.apply(lambda row:lld(row["logr_adj"], row["mean1"],row["sd1"]), axis=1)
    test_set_merged['lld2'] = test_set_merged.apply(lambda row:lld(row["logr_adj"], row["mean2"],row["sd2"]), axis=1)
    for vid in pd.unique(test_set_merged.var_id.ravel()):
        temp  = test_set_merged[test_set_merged.var_id == vid]
        nb_svtype =  reclass_nb_var(temp, p_cnv,frac_BND)
        write_output(variants[vid],vcf_out,nb_svtype)
# main function
def main():
    # parse the command line args
    args = get_args()
    # train params 
    params = pd.DataFrame()
    params = calc_params(args.tSet)
    with open('re_hom_m','r') as f:
      re_hom_m = pickle.load(f)
    f.close()
    with open('re_het_m','r') as f:
      re_het_m = pickle.load(f)
    f.close()
    # call primary function
    classify(args.vcf_in,
             args.vcf_out,
             params,
             re_hom_m,
             re_het_m,
             args.debug,
             )
# initialize the script
if __name__ == '__main__':
    try:
        sys.exit(main())
    except IOError, e:
        if e.errno != 32:  # ignore SIGPIPE
            raise 
